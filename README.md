# output-template extension for text-generation-webui

Implementation of [CBNF grammar](https://github.com/ggerganov/llama.cpp/blob/master/grammars/README.md)
for text-generation-webui.

This extension allows to force output generated by LLM to conform with expected format,
making it possible to parse it.

This is done by creating state machine which, every time when new token is to be generated, decides which
tokens are allowed to conform with defined CBNF grammar and ban (set probability to -inf) all other tokens.

To better explain the issue, here is [an example of prompt and output generated without extension demonstrating the problem](https://rentry.org/yxg7s)
and here is [same prompt and output generated with grammar](https://rentry.org/4tyci)
